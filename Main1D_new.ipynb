{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1D CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import itertools\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run auxiliary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./auxiliary_func_noprint.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose input/output dimensions and look at the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oscillon': '[dduddt-0.5**2*u+2.*u**3.]',\n",
       " 'mat': '[dduddt+(1.-0.4*tf.cos(2.*t))*u]',\n",
       " 'exp': '[dudt+0.5*u]',\n",
       " 'wave': '[dduddt+25.*u]',\n",
       " 'dho': '[dduddt+0.5*dudt+25.*u]',\n",
       " 'linear': '[dudt-1.]',\n",
       " 'delay': '[dudt-0.5*u+1.*du]',\n",
       " 'gaussian': '[dudt+0.2*t*u]',\n",
       " 'stiff': '[dudt+21.*u-tf.exp(-t)]',\n",
       " 'twofreq': '[dduddt+u+2.*tf.cos(5.*t)+6.*tf.sin(10.*t)]'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Allowed input/output values in this preliminary version are (ni=2 no=1) (ni=3 no=1) (ni=3 no=2) and (ni=1 no=1) \n",
    "\n",
    "ni=1 #number of input variables  \n",
    "no=1 #number of output solutions \n",
    "\n",
    "#LOOK AT THE PDE DICTIONARIES MATCHING THE DIMENSION REQUIREMENTS\n",
    "#################################################################################\n",
    "### outputfunction is named u, v\n",
    "### first derivatives are named dudt, dudx, dudy\n",
    "### pure second derivatives are named dduddt, dduddx, dduddy\n",
    "### mixed second derivative (as ddudtdx) need to be coded in the loss function, we will provide an automatic derivation in future updates.\n",
    "############## NOTATION #####################\n",
    "## eomdict: impose PDE constraints. The form needs to be '[ eq1 , eq2 ]' \n",
    "## ICdict: Boundary conditions on t belonging to [t0,tL].\n",
    "##         The form needs to be [ '[ u - u(t0,x,y),dudt - dudt(t0,x,y)]' , '[u - u(tL,x,y),dudt - dudt(tL,x,y)]' ] \n",
    "##         If no condition needs to be provided on some boundary just replace (u - u(t,x,y0) ) with  [none].\n",
    "## boardx: Boundary conditions on x belonging to [x0,xL].\n",
    "##         The form needs to be [ '[u - u(t,x0,y),dudx - dudx(t,x0,y)]' , '[u - u(t,xL,y),dudx - dudx(t,xL,y)]' ]   \n",
    "##         If no condition needs to be provided on some boundary just replace (u - u(t,x,y0) ) with  [none].\n",
    "## boardy: Boundary conditions in y belonging to [y0,yL].\n",
    "##         The form needs to be [ '[u - u(t,x,y0),dudy - dudy(t,x,y0)]' , '[u - u(t,x,yL),dudy - dudy(t,x,yL)]' ] \n",
    "##         If no condition needs to be provided on some boundary just write  [none].\n",
    "## wdict:  weights to be used in loss function\n",
    "##         The form needs to be [w_bulk,w_IC,w_board]\n",
    "\n",
    "eqname_dict=eqname_gen(ni,no)\n",
    "analytic=eqname_analytic(ni,no)\n",
    "sol=sol_analytic(ni,no)\n",
    "\n",
    "if ni==1:\n",
    "    eomdict,ICdict=dictgen(ni,no)\n",
    "elif ni==2:\n",
    "    eomdict,ICdict,boardx,wdict=dictgen(ni,no)\n",
    "elif ni==3:\n",
    "    eomdict,ICdict,boardx,boardy,wdict=dictgen(ni,no)\n",
    "\n",
    "eomdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#### Choose the equation of motion to be studied\n",
    "#####################################################\n",
    "### 3to1 D equations studied: ['waveb','wave','wavet', 'poisson1', 'poisson2', 'poisson3','heat1','heat2']\n",
    "### 3to2 D equations studied: ['GT','LO','NS']\n",
    "### 2to1 D equations studied: [{'wave','waveN','twave','heat','heat2f','heat0','poisson','poisson1','AdvectionDiffusion','Burgers','poisson_par','par']\n",
    "### 1to1 D equations studied: [{'oscillon', 'mat', 'exp', 'wave', 'dho', 'linear', 'delay', 'gaussian', 'stiff', 'twofreq'}]\n",
    "#####\n",
    "##Create the list of coordinate boundaries, i.e. boundaries=[t_0,t_max,x_0,x_max,y_0,y_max]\n",
    "#### Boudaries used in the paper\n",
    "#bd=[0.,1.,0.,1.,0.,1.]               # 3to1 D\n",
    "#bd=[0.,1.,0.,2.*np.pi,0.,2.*np.pi]   #'GT'\n",
    "#bd=[0.1,1.,-2.,2.,-2.,2.]            #'LO'\n",
    "#bd=[0.,10.,0.,1.,0.,1.]              #'NS'\n",
    "#bd=[0.,1.,0.,1.]                     # 2to1 D\n",
    "#bd=[0.,20.]                          # 1to1 D\n",
    "\n",
    "bd=[0.,20.]\n",
    "\n",
    "\n",
    "\n",
    "## define number of points to be sampled in the bulk, the IC and on each boundary surface\n",
    "n_bulk=2048\n",
    "batch_sz=512\n",
    "\n",
    "\n",
    "##Initialise the 2 networks\n",
    "n_l=35 #number of neurons per branch\n",
    "\n",
    "#create base frequencies to initialize the network\n",
    "pi=tf.constant(np.pi,dtype=tf.float32)\n",
    "none=tf.constant(0.,dtype=tf.float32)\n",
    "freq_t=base_freq(ni,bd)\n",
    "step=2.\n",
    "\n",
    "model=dNNsolve(ni,no,n_l,bd,step)\n",
    "\n",
    "model.save_weights(f\"model_seq_{ni}D_{n_l}nodes.h5\")\n",
    "\n",
    "\n",
    "n_l=5 #number of neurons per branch\n",
    "\n",
    "#create base frequencies to initialize the network\n",
    "pi=tf.constant(np.pi,dtype=tf.float32)\n",
    "none=tf.constant(0.,dtype=tf.float32)\n",
    "freq_t=base_freq(ni,bd)\n",
    "step=2.\n",
    "\n",
    "model=dNNsolve(ni,no,n_l,bd,step)\n",
    "\n",
    "model.save_weights(f\"model_seq_{ni}D_{n_l}nodes.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\t   log10 loss:    1.18 \n",
      "Epoch 10:\t   log10 loss:   -0.03 \n",
      "Epoch 20:\t   log10 loss:   -0.18 \n",
      "Epoch 30:\t   log10 loss:   -0.26 \n",
      "Epoch 40:\t   log10 loss:   -0.09 \n",
      "Epoch 50:\t   log10 loss:   -0.21 \n",
      "Epoch 60:\t   log10 loss:   -0.58 \n",
      "Epoch 70:\t   log10 loss:   -0.56 \n",
      "Epoch 80:\t   log10 loss:   -0.50 \n",
      "Epoch 90:\t   log10 loss:   -0.55 \n",
      "Epoch 100:\t   log10 loss:   -0.83 \n",
      "Epoch 110:\t   log10 loss:   -0.83 \n",
      "Epoch 120:\t   log10 loss:   -0.94 \n",
      "Epoch 130:\t   log10 loss:   -0.90 \n",
      "Epoch 140:\t   log10 loss:   -0.89 \n",
      "Epoch 150:\t   log10 loss:   -0.87 \n",
      "Epoch 160:\t   log10 loss:   -1.03 \n",
      "Epoch 170:\t   log10 loss:   -1.07 \n",
      "Epoch 180:\t   log10 loss:   -1.12 \n",
      "Epoch 190:\t   log10 loss:   -1.15 \n",
      "Iter: 50 loss: 0.14973475\n",
      "Iter: 100 loss: 0.103940718\n",
      "Iter: 150 loss: 0.0932078436\n",
      "Iter: 200 loss: 0.0795121938\n",
      "Iter: 250 loss: 0.172447309\n",
      "Iter: 300 loss: 0.0632626191\n",
      "Iter: 350 loss: 0.0153751606\n",
      "Iter: 400 loss: 0.0117176995\n",
      "Iter: 450 loss: 0.00839496404\n",
      "Iter: 500 loss: 0.00685335975\n",
      "Iter: 550 loss: 0.00413089059\n",
      "Iter: 600 loss: 0.00434352318\n",
      "Iter: 650 loss: 0.00185839098\n",
      "Iter: 700 loss: 0.00132830278\n",
      "Iter: 750 loss: 0.000925594533\n",
      "Iter: 800 loss: 0.000757787726\n",
      "\n",
      " EOM: mat\n",
      "\n",
      " Final log10(Loss): -3.2296\n",
      "\n",
      " Log10 of  Sqrt Mean squared error:  -3.4708\n",
      "Epoch 0:\t   log10 loss:    0.21 \n",
      "Epoch 10:\t   log10 loss:   -0.69 \n",
      "Epoch 20:\t   log10 loss:   -0.79 \n",
      "Epoch 30:\t   log10 loss:   -0.83 \n",
      "Epoch 40:\t   log10 loss:   -0.88 \n",
      "Epoch 50:\t   log10 loss:   -0.93 \n",
      "Epoch 60:\t   log10 loss:   -1.01 \n",
      "Epoch 70:\t   log10 loss:   -0.94 \n",
      "Epoch 80:\t   log10 loss:   -1.10 \n",
      "Epoch 90:\t   log10 loss:   -0.96 \n",
      "Epoch 100:\t   log10 loss:   -1.07 \n",
      "Epoch 110:\t   log10 loss:   -1.06 \n",
      "Epoch 120:\t   log10 loss:   -0.99 \n",
      "Epoch 130:\t   log10 loss:   -1.06 \n",
      "Epoch 140:\t   log10 loss:   -1.30 \n",
      "Epoch 150:\t   log10 loss:   -1.19 \n",
      "Epoch 160:\t   log10 loss:   -1.34 \n",
      "Epoch 170:\t   log10 loss:   -1.30 \n",
      "Epoch 180:\t   log10 loss:   -1.34 \n",
      "Epoch 190:\t   log10 loss:   -1.41 \n",
      "Iter: 50 loss: 0.166605711\n",
      "Iter: 100 loss: 3.39935803\n",
      "Iter: 150 loss: 0.0149694066\n",
      "Iter: 200 loss: 0.00171939633\n",
      "Iter: 250 loss: 0.00045012412\n",
      "Iter: 300 loss: 0.000543688133\n",
      "\n",
      " EOM: exp\n",
      "\n",
      " Final log10(Loss): -3.4354\n",
      "\n",
      " Log10 of  Sqrt Mean squared error:  -3.9414\n",
      "Epoch 0:\t   log10 loss:    1.21 \n",
      "Epoch 10:\t   log10 loss:   -0.17 \n",
      "Epoch 20:\t   log10 loss:   -0.11 \n",
      "Epoch 30:\t   log10 loss:   -0.28 \n",
      "Epoch 40:\t   log10 loss:   -0.28 \n",
      "Epoch 50:\t   log10 loss:   -0.44 \n",
      "Epoch 60:\t   log10 loss:   -0.31 \n",
      "Epoch 70:\t   log10 loss:   -0.45 \n",
      "Epoch 80:\t   log10 loss:   -0.44 \n",
      "Epoch 90:\t   log10 loss:   -0.33 \n",
      "Epoch 100:\t   log10 loss:   -0.33 \n",
      "Epoch 110:\t   log10 loss:   -0.46 \n",
      "Epoch 120:\t   log10 loss:   -0.79 \n",
      "Epoch 130:\t   log10 loss:   -0.81 \n",
      "Epoch 140:\t   log10 loss:   -0.77 \n",
      "Epoch 150:\t   log10 loss:   -0.80 \n",
      "Epoch 160:\t   log10 loss:   -1.01 \n",
      "Epoch 170:\t   log10 loss:   -1.10 \n",
      "Epoch 180:\t   log10 loss:   -1.09 \n",
      "Epoch 190:\t   log10 loss:   -1.06 \n",
      "Iter: 50 loss: 141.812637\n",
      "Iter: 100 loss: 0.0557310879\n",
      "Iter: 150 loss: 7.35238552\n",
      "Iter: 200 loss: 0.0222395472\n",
      "Iter: 250 loss: 0.0018085785\n",
      "Iter: 300 loss: 0.000743479119\n",
      "Iter: 350 loss: 0.000443703117\n",
      "Iter: 400 loss: 0.00031665212\n",
      "Iter: 450 loss: 8.93023753e-05\n",
      "Iter: 500 loss: 4.60595111e-05\n",
      "Iter: 550 loss: 3.33616517e-05\n",
      "Iter: 600 loss: 2.80603017e-05\n",
      "Iter: 650 loss: 1.316821e-05\n",
      "\n",
      " EOM: wave\n",
      "\n",
      " Final log10(Loss): -4.8807\n",
      "\n",
      " Log10 of  Sqrt Mean squared error:  -5.6726\n",
      "Epoch 0:\t   log10 loss:    1.22 \n",
      "Epoch 10:\t   log10 loss:   -0.13 \n",
      "Epoch 20:\t   log10 loss:   -0.24 \n",
      "Epoch 30:\t   log10 loss:   -0.20 \n",
      "Epoch 40:\t   log10 loss:   -0.25 \n",
      "Epoch 50:\t   log10 loss:   -0.32 \n",
      "Epoch 60:\t   log10 loss:   -0.46 \n",
      "Epoch 70:\t   log10 loss:   -0.51 \n",
      "Epoch 80:\t   log10 loss:   -0.41 \n",
      "Epoch 90:\t   log10 loss:   -0.48 \n",
      "Epoch 100:\t   log10 loss:   -0.43 \n",
      "Epoch 110:\t   log10 loss:   -0.73 \n",
      "Epoch 120:\t   log10 loss:   -0.80 \n",
      "Epoch 130:\t   log10 loss:   -0.70 \n",
      "Epoch 140:\t   log10 loss:   -0.73 \n",
      "Epoch 150:\t   log10 loss:   -0.78 \n",
      "Epoch 160:\t   log10 loss:   -0.75 \n",
      "Epoch 170:\t   log10 loss:   -1.03 \n",
      "Epoch 180:\t   log10 loss:   -1.05 \n",
      "Epoch 190:\t   log10 loss:   -1.03 \n",
      "Iter: 50 loss: 0.398310453\n",
      "Iter: 100 loss: 0.102886103\n",
      "Iter: 150 loss: 0.0623875223\n",
      "Iter: 200 loss: 0.507627547\n",
      "Iter: 250 loss: 0.0373252034\n",
      "Iter: 300 loss: 0.0013255995\n",
      "Iter: 350 loss: 0.000679569\n",
      "Iter: 400 loss: 0.000491672952\n",
      "Iter: 450 loss: 0.000310783\n",
      "Iter: 500 loss: 0.000146324281\n",
      "\n",
      " EOM: dho\n",
      "\n",
      " Final log10(Loss): -4.0553\n",
      "\n",
      " Log10 of  Sqrt Mean squared error:  -5.1961\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function random_sampling.<locals>.random_sampling_1D at 0x160e465f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 0:\t   log10 loss:    0.23 \n",
      "Epoch 10:\t   log10 loss:   -0.22 \n",
      "Epoch 20:\t   log10 loss:   -0.29 \n",
      "Epoch 30:\t   log10 loss:   -0.44 \n",
      "Epoch 40:\t   log10 loss:   -0.56 \n",
      "Epoch 50:\t   log10 loss:   -0.63 \n",
      "Epoch 60:\t   log10 loss:   -0.78 \n",
      "Epoch 70:\t   log10 loss:   -0.77 \n",
      "Epoch 80:\t   log10 loss:   -0.86 \n",
      "Epoch 90:\t   log10 loss:   -0.75 \n",
      "Epoch 100:\t   log10 loss:   -0.83 \n",
      "Epoch 110:\t   log10 loss:   -0.95 \n",
      "Epoch 120:\t   log10 loss:   -0.82 \n",
      "Epoch 130:\t   log10 loss:   -0.93 \n",
      "Epoch 140:\t   log10 loss:   -0.84 \n",
      "Epoch 150:\t   log10 loss:   -0.87 \n",
      "Epoch 160:\t   log10 loss:   -0.98 \n",
      "Epoch 170:\t   log10 loss:   -0.89 \n",
      "Epoch 180:\t   log10 loss:   -1.03 \n",
      "Epoch 190:\t   log10 loss:   -1.05 \n",
      "Iter: 50 loss: 0.0687391162\n",
      "Iter: 100 loss: 1.66992879\n",
      "Iter: 150 loss: 0.0169295277\n",
      "Iter: 200 loss: 0.00484028971\n",
      "Iter: 250 loss: 0.00384906866\n",
      "Iter: 300 loss: 0.00134221616\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function function_factory.<locals>.assign_new_model_parameters at 0x160e46050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " EOM: linear\n",
      "\n",
      " Final log10(Loss): -3.1576\n",
      "\n",
      " Log10 of  Sqrt Mean squared error:  -2.9996\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function random_sampling.<locals>.random_sampling_1D at 0x161735e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 0:\t   log10 loss:    0.10 \n",
      "Epoch 10:\t   log10 loss:   -0.65 \n",
      "Epoch 20:\t   log10 loss:   -0.85 \n",
      "Epoch 30:\t   log10 loss:   -0.81 \n",
      "Epoch 40:\t   log10 loss:   -0.88 \n",
      "Epoch 50:\t   log10 loss:   -0.96 \n",
      "Epoch 60:\t   log10 loss:   -0.92 \n",
      "Epoch 70:\t   log10 loss:   -1.20 \n",
      "Epoch 80:\t   log10 loss:   -1.21 \n",
      "Epoch 90:\t   log10 loss:   -1.28 \n",
      "Epoch 100:\t   log10 loss:   -1.24 \n",
      "Epoch 110:\t   log10 loss:   -1.33 \n",
      "Epoch 120:\t   log10 loss:   -1.26 \n",
      "Epoch 130:\t   log10 loss:   -1.34 \n",
      "Epoch 140:\t   log10 loss:   -1.46 \n",
      "Epoch 150:\t   log10 loss:   -1.27 \n",
      "Epoch 160:\t   log10 loss:   -1.32 \n",
      "Epoch 170:\t   log10 loss:   -1.23 \n",
      "Epoch 180:\t   log10 loss:   -1.67 \n",
      "Epoch 190:\t   log10 loss:   -1.61 \n",
      "Iter: 50 loss: 0.798267663\n",
      "Iter: 100 loss: 0.0651365891\n",
      "Iter: 150 loss: 0.00388110732\n",
      "Iter: 200 loss: 0.00152970653\n",
      "Iter: 250 loss: 0.00122866477\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function function_factory.<locals>.assign_new_model_parameters at 0x16170f7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " EOM: delay\n",
      "\n",
      " Final log10(Loss): -2.9531\n",
      "\n",
      " Log10 of  Sqrt Mean squared error:  -2.3302\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function random_sampling.<locals>.random_sampling_1D at 0x1614967a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Garfield/anaconda3/envs/tensor_flow/lib/python3.7/site-packages/ddeint/ddeint.py:145: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array([g(tt[0])] + results)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\t   log10 loss:    0.33 \n",
      "Epoch 10:\t   log10 loss:   -0.63 \n",
      "Epoch 20:\t   log10 loss:   -0.66 \n",
      "Epoch 30:\t   log10 loss:   -0.87 \n",
      "Epoch 40:\t   log10 loss:   -0.91 \n",
      "Epoch 50:\t   log10 loss:   -0.86 \n",
      "Epoch 60:\t   log10 loss:   -0.96 \n",
      "Epoch 70:\t   log10 loss:   -0.87 \n",
      "Epoch 80:\t   log10 loss:   -1.12 \n",
      "Epoch 90:\t   log10 loss:   -1.32 \n",
      "Epoch 100:\t   log10 loss:   -1.17 \n",
      "Epoch 110:\t   log10 loss:   -1.30 \n",
      "Epoch 120:\t   log10 loss:   -1.26 \n",
      "Epoch 130:\t   log10 loss:   -1.36 \n",
      "Epoch 140:\t   log10 loss:   -1.55 \n",
      "Epoch 150:\t   log10 loss:   -1.52 \n",
      "Epoch 160:\t   log10 loss:   -1.54 \n",
      "Epoch 170:\t   log10 loss:   -1.55 \n",
      "Epoch 180:\t   log10 loss:   -1.62 \n",
      "Epoch 190:\t   log10 loss:   -1.57 \n",
      "Iter: 50 loss: 0.0103164511\n",
      "Iter: 100 loss: 0.00985741429\n",
      "Iter: 150 loss: 0.00586510496\n",
      "Iter: 200 loss: 0.0643138513\n",
      "Iter: 250 loss: 0.00123847683\n",
      "Iter: 300 loss: 0.00047045527\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function function_factory.<locals>.assign_new_model_parameters at 0x161496950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " EOM: gaussian\n",
      "\n",
      " Final log10(Loss): -3.2199\n",
      "\n",
      " Log10 of  Sqrt Mean squared error:  -4.1138\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function random_sampling.<locals>.random_sampling_1D at 0x1619a23b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 0:\t   log10 loss:    0.87 \n",
      "Epoch 10:\t   log10 loss:   -0.22 \n",
      "Epoch 20:\t   log10 loss:   -0.31 \n",
      "Epoch 30:\t   log10 loss:   -0.29 \n",
      "Epoch 40:\t   log10 loss:   -0.31 \n",
      "Epoch 50:\t   log10 loss:   -0.38 \n",
      "Epoch 60:\t   log10 loss:   -0.57 \n",
      "Epoch 70:\t   log10 loss:   -0.64 \n",
      "Epoch 80:\t   log10 loss:   -0.62 \n",
      "Epoch 90:\t   log10 loss:   -0.62 \n",
      "Epoch 100:\t   log10 loss:   -0.60 \n",
      "Epoch 110:\t   log10 loss:   -0.70 \n",
      "Epoch 120:\t   log10 loss:   -0.70 \n",
      "Epoch 130:\t   log10 loss:   -0.62 \n",
      "Epoch 140:\t   log10 loss:   -0.71 \n",
      "Epoch 150:\t   log10 loss:   -0.70 \n",
      "Epoch 160:\t   log10 loss:   -0.90 \n",
      "Epoch 170:\t   log10 loss:   -0.91 \n",
      "Epoch 180:\t   log10 loss:   -0.84 \n",
      "Epoch 190:\t   log10 loss:   -0.94 \n",
      "Iter: 50 loss: 12.7645788\n",
      "Iter: 100 loss: 2.18090796\n",
      "Iter: 150 loss: 602.697205\n",
      "Iter: 200 loss: 0.103987254\n",
      "Iter: 250 loss: 0.0922684744\n",
      "Iter: 300 loss: 0.0153073054\n",
      "Iter: 350 loss: 0.0130176786\n",
      "Iter: 400 loss: 0.00591701921\n",
      "Iter: 450 loss: 0.00302485726\n",
      "Iter: 500 loss: 0.00159073866\n",
      "Iter: 550 loss: 0.00112091901\n",
      "Iter: 600 loss: 0.000735694426\n",
      "Iter: 650 loss: 0.000687099469\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function function_factory.<locals>.assign_new_model_parameters at 0x1619599e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " EOM: stiff\n",
      "\n",
      " Final log10(Loss): -3.1630\n",
      "\n",
      " Log10 of  Sqrt Mean squared error:  -4.6648\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function random_sampling.<locals>.random_sampling_1D at 0x1609b3b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 0:\t   log10 loss:    1.08 \n",
      "Epoch 10:\t   log10 loss:    0.24 \n",
      "Epoch 20:\t   log10 loss:   -0.02 \n",
      "Epoch 30:\t   log10 loss:   -0.13 \n",
      "Epoch 40:\t   log10 loss:   -0.12 \n",
      "Epoch 50:\t   log10 loss:   -0.12 \n",
      "Epoch 60:\t   log10 loss:    0.01 \n",
      "Epoch 70:\t   log10 loss:   -0.55 \n",
      "Epoch 80:\t   log10 loss:   -0.41 \n",
      "Epoch 90:\t   log10 loss:   -0.49 \n",
      "Epoch 100:\t   log10 loss:   -0.49 \n",
      "Epoch 110:\t   log10 loss:   -0.82 \n",
      "Epoch 120:\t   log10 loss:   -0.67 \n",
      "Epoch 130:\t   log10 loss:   -0.74 \n",
      "Epoch 140:\t   log10 loss:   -1.04 \n",
      "Epoch 150:\t   log10 loss:   -1.11 \n",
      "Epoch 160:\t   log10 loss:   -1.06 \n",
      "Epoch 170:\t   log10 loss:   -1.09 \n",
      "Epoch 180:\t   log10 loss:   -1.09 \n",
      "Epoch 190:\t   log10 loss:   -0.99 \n",
      "Iter: 50 loss: 0.454280496\n",
      "Iter: 100 loss: 0.157438\n",
      "Iter: 150 loss: 3.74577498\n",
      "Iter: 200 loss: 0.152374953\n",
      "Iter: 250 loss: 0.0157787409\n",
      "Iter: 300 loss: 0.0329948366\n",
      "Iter: 350 loss: 0.00309425127\n",
      "Iter: 400 loss: 0.00222672126\n",
      "Iter: 450 loss: 0.00309953932\n",
      "Iter: 500 loss: 0.00321037625\n",
      "Iter: 550 loss: 0.00101869099\n",
      "Iter: 600 loss: 0.000696991861\n",
      "Iter: 650 loss: 0.000250254729\n",
      "Iter: 700 loss: 0.000120745135\n",
      "Iter: 750 loss: 0.000111980349\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function function_factory.<locals>.assign_new_model_parameters at 0x1609b38c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " EOM: twofreq\n",
      "\n",
      " Final log10(Loss): -3.9507\n",
      "\n",
      " Log10 of  Sqrt Mean squared error:  -4.4246\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function random_sampling.<locals>.random_sampling_1D at 0x16115fd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 0:\t   log10 loss:   -0.30 \n",
      "Epoch 10:\t   log10 loss:   -1.34 \n",
      "Epoch 20:\t   log10 loss:   -1.43 \n",
      "Epoch 30:\t   log10 loss:   -1.86 \n",
      "Epoch 40:\t   log10 loss:   -1.55 \n",
      "Epoch 50:\t   log10 loss:   -1.85 \n",
      "Epoch 60:\t   log10 loss:   -1.88 \n",
      "Epoch 70:\t   log10 loss:   -1.92 \n",
      "Epoch 80:\t   log10 loss:   -1.81 \n",
      "Epoch 90:\t   log10 loss:   -1.71 \n",
      "Epoch 100:\t   log10 loss:   -2.03 \n",
      "Epoch 110:\t   log10 loss:   -2.23 \n",
      "Epoch 120:\t   log10 loss:   -2.23 \n",
      "Epoch 130:\t   log10 loss:   -1.98 \n",
      "Epoch 140:\t   log10 loss:   -2.28 \n",
      "Epoch 150:\t   log10 loss:   -2.33 \n",
      "Epoch 160:\t   log10 loss:   -2.70 \n",
      "Epoch 170:\t   log10 loss:   -2.63 \n",
      "Epoch 180:\t   log10 loss:   -2.72 \n",
      "Epoch 190:\t   log10 loss:   -2.60 \n",
      "Iter: 50 loss: 0.0016782498\n",
      "Iter: 100 loss: 0.00122805324\n",
      "Iter: 150 loss: 0.000488123187\n",
      "Iter: 200 loss: 0.000159897099\n",
      "Iter: 250 loss: 0.000114170733\n",
      "Iter: 300 loss: 0.000107658649\n",
      "Iter: 350 loss: 9.34091149e-05\n",
      "Iter: 400 loss: 7.45340512e-05\n",
      "Iter: 450 loss: 6.57681812e-05\n",
      "Iter: 500 loss: 5.77908722e-05\n",
      "Iter: 550 loss: 4.60118208e-05\n",
      "Iter: 600 loss: 1.61753414e-05\n",
      "Iter: 650 loss: 5.82461507e-06\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function function_factory.<locals>.assign_new_model_parameters at 0x16115fd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " EOM: oscillon\n",
      "\n",
      " Final log10(Loss): -5.2350\n",
      "\n",
      " Log10 of  Sqrt Mean squared error:  -5.5197\n"
     ]
    }
   ],
   "source": [
    "epochs_adam=200 \n",
    "\n",
    "f= open(\"1to1_results.txt\",\"w+\")\n",
    "oneD_dict=['mat','exp','wave','dho','linear','delay','gaussian','stiff','twofreq','oscillon']\n",
    "\n",
    "\n",
    "for eom in oneD_dict:\n",
    "    \n",
    "    if eom=='oscillon':\n",
    "        step=2.\n",
    "        n_l=5\n",
    "        model=dNNsolve(ni,no,n_l,bd,step)\n",
    "        model.save_weights(f\"model_seq_{ni}D_{n_l}nodes.h5\")\n",
    "    else:\n",
    "        step=2.\n",
    "        n_l=35\n",
    "        model=dNNsolve(ni,no,n_l,bd,step)\n",
    "        \n",
    "    \n",
    "    X_data = (random_sampling(ni))(bd,n_bulk)\n",
    "    #Define ic, bc and bulk counters (I_t0,I_tL,I_bulk)\n",
    "    I=counters(ni)(bd,X_data)\n",
    "    fake_output=tf.concat([X_data,I],axis=1)\n",
    "    step=2.\n",
    "    inputs=[X_data]\n",
    "\n",
    "    ########################\n",
    "    start=time.time() \n",
    "    #initialization of models\n",
    "    model.load_weights(f\"model_seq_{ni}D_{n_l}nodes.h5\") #Restore weights to original values at each iteration\n",
    "    loss_fun=to_loss_1to1(eom)  \n",
    "\n",
    "\n",
    "    # an educated guess for the oscillon central amplitude\n",
    "    if ni==1 and eom=='oscillon':\n",
    "        u0guess=tf.constant(0.6)\n",
    "\n",
    "    #Initialise BFGS method and compile the model\n",
    "    func = function_factory(model, loss_fun, fake_output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "                           loss=loss_fun,run_eagerly=False)\n",
    "\n",
    "    #Training with Adam\n",
    "    hist = model.fit(x=inputs, y=fake_output, batch_size = batch_sz, epochs=epochs_adam, verbose=0, callbacks = \n",
    "                       [Print_Loss_Every_so_many_Epochs(),tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', mode='min', factor=1./2., patience=30, min_lr=1e-4)])\n",
    "\n",
    "\n",
    "    #Training with BFGS\n",
    "    init_params = tf.dynamic_stitch(func.idx, model.trainable_variables)\n",
    "    results = tfp.optimizer.bfgs_minimize(value_and_gradients_function=func, initial_position=init_params,tolerance=1e-20, max_iterations=5000)    \n",
    "    func.assign_new_model_parameters(results.position)\n",
    "\n",
    "\n",
    "\n",
    "    #Store loss data\n",
    "    loss_adam=np.array(hist.history['loss'],dtype=np.float32) \n",
    "    history_lbfgs=np.array(func.history)\n",
    "    hist_lbfgs=np.array(history_lbfgs[:,0])\n",
    "    loss=np.concatenate((loss_adam,hist_lbfgs))\n",
    "    end=time.time()\n",
    "\n",
    "    n_plt=300\n",
    "    pred, smse, tplt=points_plt_mse(ni,no,bd,model,sol) \n",
    "\n",
    "\n",
    "    eps=1e-20 ##small parameter to avoid inf values\n",
    "    print('\\n EOM: ' + eom)\n",
    "    print('\\n Final log10(Loss): %.4f' % (np.log10(loss[-1])+eps))\n",
    "    print('\\n Log10 of  Sqrt Mean squared error:  %.4f' % (np.log10(smse+1e-20)+eps))\n",
    "    f.write('\\n EOM: ' + eom)\n",
    "    f.write('\\n Neurons per branch:  %s' % (n_l))\n",
    "    f.write('\\n Epochs:  %s' % (loss.size))\n",
    "    f.write('\\n Total Time: %.4f' % (end-start))\n",
    "    f.write('\\n Final log10(Loss Adam): %.4f' % (np.log10(loss_adam[-1])+eps))\n",
    "    f.write('\\n Final log10(Loss): %.4f' % (np.log10(loss[-1])+eps))\n",
    "    f.write('\\n Log10 of  Sqrt Mean squared error:  %.4f' % (np.log10(smse+1e-20)+eps))\n",
    "    f.write('\\n log10(Loss bulk): %.4f log10(Loss IC): %.4f log10(Loss board): %.4f' % (np.log10(eps+np.array(history_lbfgs[:,1])[-1]),np.log10(eps+np.array(history_lbfgs[:,2])[-1]),np.log10(eps+np.array(history_lbfgs[:,3])[-1])))\n",
    "    f.write('\\n #######################################################')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15ff08450>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_u=sol(eom,tplt)\n",
    "predu=model(tplt)\n",
    "\n",
    "fig, axes = plt.subplots(1, sharex=True, figsize=(8, 5))\n",
    "axes.set_ylabel(\"log10(Loss)\", fontsize=14)\n",
    "axes.set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes.plot(tplt, true_u, label = f\"Adam\", color = 'blue')\n",
    "axes.plot(tplt, predu , label = f\"BFGS\", color = 'red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
