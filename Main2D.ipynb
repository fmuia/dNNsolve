{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import itertools\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run auxiliary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./auxiliary_func_noprint.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose input/output dimensions and look at the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wave': '[dduddt-1.**2*dduddx]',\n",
       " 'waveN': '[dduddt-1.**2*dduddx]',\n",
       " 'twave': '[dudt-1.**2*dudx]',\n",
       " 'heat': '[dudt-0.05*dduddx]',\n",
       " 'heat2f': '[dudt-0.01*dduddx]',\n",
       " 'heat0': '[dudt-0.05*dduddx]',\n",
       " 'poisson': '[dduddt+dduddx + 2. * np.pi**2. * tf.sin(np.pi * t) * tf.sin(np.pi * x)]',\n",
       " 'poisson1': '[dduddt+dduddx-10.*(t-1)*tf.math.cos(5.*x)+25.*(t-1)*(x-1)*tf.math.sin(5.*x)]',\n",
       " 'AdvectionDiffusion': '[dudt - 0.25 * dduddx]',\n",
       " 'Burgers': '[dudt + u * dudx - 0.25 * dduddx]',\n",
       " 'poisson_par': '[(dduddt+dduddx-tf.exp(-(t**2+10.*x**2)))]',\n",
       " 'par': '[(dduddt+dduddx-4.)]'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Allowed input/output values in this preliminary version are (ni=2 no=1) (ni=3 no=1) (ni=3 no=2) and (ni=1 no=1) \n",
    "\n",
    "ni=2 #number of input variables  \n",
    "no=1 #number of output solutions \n",
    "\n",
    "#LOOK AT THE PDE DICTIONARIES MATCHING THE DIMENSION REQUIREMENTS\n",
    "#################################################################################\n",
    "### outputfunction is named u, v\n",
    "### first derivatives are named dudt, dudx, dudy\n",
    "### pure second derivatives are named dduddt, dduddx, dduddy\n",
    "### mixed second derivative (as ddudtdx) need to be coded in the loss function, we will provide an automatic derivation in future updates.\n",
    "############## NOTATION #####################\n",
    "## eomdict: impose PDE constraints. The form needs to be '[ eq1 , eq2 ]' \n",
    "## ICdict: Boundary conditions on t belonging to [t0,tL].\n",
    "##         The form needs to be [ '[ u - u(t0,x,y),dudt - dudt(t0,x,y)]' , '[u - u(tL,x,y),dudt - dudt(tL,x,y)]' ] \n",
    "##         If no condition needs to be provided on some boundary just replace (u - u(t,x,y0) ) with  [none].\n",
    "## boardx: Boundary conditions on x belonging to [x0,xL].\n",
    "##         The form needs to be [ '[u - u(t,x0,y),dudx - dudx(t,x0,y)]' , '[u - u(t,xL,y),dudx - dudx(t,xL,y)]' ]   \n",
    "##         If no condition needs to be provided on some boundary just replace (u - u(t,x,y0) ) with  [none].\n",
    "## boardy: Boundary conditions in y belonging to [y0,yL].\n",
    "##         The form needs to be [ '[u - u(t,x,y0),dudy - dudy(t,x,y0)]' , '[u - u(t,x,yL),dudy - dudy(t,x,yL)]' ] \n",
    "##         If no condition needs to be provided on some boundary just write  [none].\n",
    "## wdict:  weights to be used in loss function\n",
    "##         The form needs to be [w_bulk,w_IC,w_board]\n",
    "\n",
    "eqname_dict=eqname_gen(ni,no)\n",
    "analytic=eqname_analytic(ni,no)\n",
    "sol=sol_analytic(ni,no)\n",
    "\n",
    "if ni==1:\n",
    "    eomdict,ICdict=dictgen(ni,no)\n",
    "elif ni==2:\n",
    "    eomdict,ICdict,boardx,wdict=dictgen(ni,no)\n",
    "elif ni==3:\n",
    "    eomdict,ICdict,boardx,boardy,wdict=dictgen(ni,no)\n",
    "\n",
    "eomdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#### Choose the equation of motion to be studied\n",
    "#####################################################\n",
    "### 3to1 D equations studied: ['waveb','wave','wavet', 'poisson1', 'poisson2', 'poisson3','heat1','heat2']\n",
    "### 3to2 D equations studied: ['GT','LO','NS']\n",
    "### 2to1 D equations studied: [{'wave','waveN','twave','heat','heat2f','heat0','poisson','poisson1','AdvectionDiffusion','Burgers','poisson_par','par']\n",
    "### 1to1 D equations studied: [{'oscillon', 'mat', 'exp', 'wave', 'dho', 'linear', 'delay', 'gaussian', 'stiff', 'twofreq'}]\n",
    "#####\n",
    "##Create the list of coordinate boundaries, i.e. boundaries=[t_0,t_max,x_0,x_max,y_0,y_max]\n",
    "#### Boudaries used in the paper\n",
    "#bd=[0.,1.,0.,1.,0.,1.]               # 3to1 D\n",
    "#bd=[0.,1.,0.,2.*np.pi,0.,2.*np.pi]   #'GT'\n",
    "#bd=[0.1,1.,-2.,2.,-2.,2.]            #'LO'\n",
    "#bd=[0.,10.,0.,1.,0.,1.]              #'NS'\n",
    "#bd=[0.,1.,0.,1.]                     # 2to1 D\n",
    "#bd=[0.,20.]                          # 1to1 D\n",
    "\n",
    "bd=[0.,1.,0.,1.] \n",
    "\n",
    "\n",
    "\n",
    "## define number of points to be sampled in the bulk, the IC and on each boundary surface\n",
    "## (for the 1D case (n_IC,n_board) will effectively evaluate to (1,0), irrespective of the chosen values)\n",
    "n_bulk=1000\n",
    "n_IC=200\n",
    "n_board=200\n",
    "\n",
    "\n",
    "##Initialise the network\n",
    "n_l=10 #number of neurons per branch\n",
    "\n",
    "#create base frequencies to initialize the network\n",
    "pi=tf.constant(np.pi,dtype=tf.float32)\n",
    "none=tf.constant(0.,dtype=tf.float32)\n",
    "\n",
    "freq_t,freq_x=base_freq(ni,bd)\n",
    "\n",
    "step=1.\n",
    "model=dNNsolve(ni,no,n_l,bd,step)\n",
    "\n",
    "model.save_weights(f\"model_seq_{ni}D_{n_l}nodes.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_adam=400  \n",
    "batch_sz=256\n",
    "\n",
    "f= open(\"2to1_results.txt\",\"w+\")\n",
    "twoD_dict={'disk':['par','poisson_par'],\n",
    "           'rect':['wave','waveN','twave','heat','heat2f','heat0','poisson1','poisson','AdvectionDiffusion','Burgers']}\n",
    "for domain in twoD_dict:\n",
    "    for eom in twoD_dict[domain]:\n",
    "\n",
    "\n",
    "        #Define dataset from random sampling the domain\n",
    "        \n",
    "        if domain=='rect':\n",
    "            X_data, t, x=  (random_sampling(ni,domain))(bd,n_bulk,n_IC,n_board)\n",
    "            #Define IC, boundary and bulk counters (I_t0,I_tL,I_x0,I_xL,I_y0,I_yL,I_bulk)\n",
    "            I=counters(ni,'rect')(bd,t,x)\n",
    "            fake_output=tf.concat([X_data,I],axis=1)\n",
    "            inputs=[t, x]\n",
    "        if domain=='disk':\n",
    "            X_data, t, x=  (random_sampling(ni,domain))(bd,n_bulk,n_board)\n",
    "            #Define IC, boundary and bulk counters (I_t0,I_tL,I_x0,I_xL,I_y0,I_yL,I_bulk)\n",
    "            I=counters(ni,'disk')(bd,t,x)\n",
    "            fake_output=tf.concat([X_data,I],axis=1)\n",
    "            inputs=[t, x]\n",
    "        \n",
    "        ########################\n",
    "        start=time.time() \n",
    "        #initialization of models\n",
    "        model.load_weights(f\"model_seq_{ni}D_{n_l}nodes.h5\") #Restore weights to original values at each iteration\n",
    "        loss_fun=to_loss_2to1(eom,domain)\n",
    "\n",
    "        #Initialise BFGS method and compile the model\n",
    "        func = function_factory(model, loss_fun, fake_output)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "                               loss=loss_fun,run_eagerly=False)\n",
    "\n",
    "        #Training with Adam\n",
    "        hist = model.fit(x=inputs, y=fake_output, batch_size = batch_sz, epochs=epochs_adam, verbose=0, callbacks = \n",
    "                           [tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', mode='min', factor=1./2., patience=30, min_lr=1e-4)])\n",
    "\n",
    "\n",
    "        #Training with BFGS\n",
    "        init_params = tf.dynamic_stitch(func.idx, model.trainable_variables)\n",
    "        results = tfp.optimizer.bfgs_minimize(value_and_gradients_function=func, initial_position=init_params,tolerance=1e-20, max_iterations=5000)    \n",
    "        func.assign_new_model_parameters(results.position)\n",
    "\n",
    "\n",
    "\n",
    "        #Store loss data\n",
    "        loss_adam=np.array(hist.history['loss'],dtype=np.float32) \n",
    "        history_lbfgs=np.array(func.history)\n",
    "        hist_lbfgs=np.array(history_lbfgs[:,0])\n",
    "        loss=np.concatenate((loss_adam,hist_lbfgs))\n",
    "        end=time.time()\n",
    "\n",
    "        if domain=='rect':\n",
    "            n_plt=51\n",
    "            pred, smse, tplt, xplt=points_plt_mse(ni,no,bd,model,sol,domain='rect')\n",
    "\n",
    "        elif domain=='disk':\n",
    "            n_plt=51\n",
    "            pred, smse, tplt, xplt=points_plt_mse(ni,no,bd,model,sol,domain='disk')\n",
    "\n",
    "        eps=1e-20 ##small parameter to avoid inf values\n",
    "        f.write('\\n EOM: ' + eom)\n",
    "        f.write('\\n Neurons per branch:  %s' % (n_l))\n",
    "        f.write('\\n Epochs:  %s' % (loss.size))\n",
    "        f.write('\\n Total Time: %.4f' % (end-start))\n",
    "        f.write('\\n Final log10(Loss Adam): %.4f' % (np.log10(loss_adam[-1])+eps))\n",
    "        f.write('\\n Final log10(Loss): %.4f' % (np.log10(loss[-1])+eps))\n",
    "        f.write('\\n Log10 of  Sqrt Mean squared error:  %.4f' % (np.log10(smse+1e-20)+eps))\n",
    "        f.write('\\n log10(Loss bulk): %.4f log10(Loss IC): %.4f log10(Loss board): %.4f' % (np.log10(eps+np.array(history_lbfgs[:,1])[-1]),np.log10(eps+np.array(history_lbfgs[:,2])[-1]),np.log10(eps+np.array(history_lbfgs[:,3])[-1])))\n",
    "        f.write('\\n #######################################################')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
